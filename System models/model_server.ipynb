{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXrhJL5_q-M_"
      },
      "source": [
        "#FLASK SERVER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbJbJph54YKi",
        "outputId": "f1c0b593-cec6-4c40-a48c-86d94f334faf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-6.0.0.tar.gz (681 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m681.2/681.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-6.0.0-py3-none-any.whl size=19867 sha256=41f5d141af298f8ae5277aa3f2970b4ee9eb9a8dd0ed3c49f252b6afec8a90c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/42/78/0c3d438d7f5730451a25f7ac6cbf4391759d22a67576ed7c2c\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-6.0.0\n"
          ]
        }
      ],
      "source": [
        "# For public server\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3F4p6t84YM3"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, Response, jsonify\n",
        "from pyngrok import ngrok\n",
        "# from multiprocessing import Process\n",
        "import threading\n",
        "import base64\n",
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L13ki6raY8YS"
      },
      "outputs": [],
      "source": [
        "# List images as json\n",
        "def list_images(folder, image_type):\n",
        "    image_files = os.listdir(folder)\n",
        "    images = []\n",
        "    for file_name in image_files:\n",
        "        with open(os.path.join(folder, file_name), 'rb') as f:\n",
        "            image_bytes = f.read()\n",
        "            images.append({\n",
        "                'name': file_name,\n",
        "                'type': image_type,\n",
        "                'data': base64.b64encode(image_bytes).decode('utf-8')\n",
        "            })\n",
        "    return images\n",
        "\n",
        "# Recreate folder\n",
        "def recreate(folder):\n",
        "    # Check if the folder exists\n",
        "    if os.path.exists(folder):\n",
        "        # Remove the folder and its contents\n",
        "        shutil.rmtree(folder)\n",
        "    # Create a single directory\n",
        "    os.mkdir(folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcNBfnARXSiY"
      },
      "outputs": [],
      "source": [
        "input_path = '/content/input/input.mp4'\n",
        "output_path = '/content/output/output.mp4'\n",
        "intermid_output = '/content/inter_output2.mp4'\n",
        "\n",
        "input_criminal_folder = '/content/drive/MyDrive/TheProject/criminal4'\n",
        "image_folder = '/content/image'\n",
        "output_face_folder = '/content/face'\n",
        "fall_image_folder = '/content/fall'\n",
        "crash_folder = '/content/crash'\n",
        "\n",
        "# 'begin', 'finished', 'processing'\n",
        "status = 'begin'\n",
        "\n",
        "frame_count = 1\n",
        "frame_number = -1\n",
        "my_model = ''\n",
        "id = ''\n",
        "\n",
        "def process():\n",
        "    global input_criminal_folder\n",
        "    global image_folder\n",
        "    global output_face_folder\n",
        "    global fall_image_folder\n",
        "    global mask_image_folder\n",
        "    global crash_folder\n",
        "    global my_model\n",
        "    global status\n",
        "\n",
        "    global frame_number\n",
        "    global frame_count\n",
        "\n",
        "    # Clear folders\n",
        "    recreate(image_folder)\n",
        "    recreate(output_face_folder)\n",
        "    recreate(fall_image_folder)\n",
        "    recreate(crash_folder)\n",
        "\n",
        "    start=time.time()\n",
        "    try:\n",
        "        status = 'processing'\n",
        "        if my_model == 'fight':\n",
        "            list_criminal_images = os.listdir(input_criminal_folder)\n",
        "\n",
        "            fightDetection2(input_path,output_path,image_folder,input_criminal_folder,list_criminal_images,output_face_folder,face_model=False)\n",
        "\n",
        "        # Fight, Face\n",
        "        elif my_model == 'fight_face':\n",
        "            list_criminal_images = os.listdir(input_criminal_folder)\n",
        "            fightDetection2(input_path,output_path,image_folder,input_criminal_folder,list_criminal_images,output_face_folder,face_model=True)\n",
        "\n",
        "        # Fastest with max models number\n",
        "        # Fight, Face, Fall, Crash\n",
        "        elif my_model == 'fight_fall_crash':\n",
        "            list_criminal_images = os.listdir(input_criminal_folder)\n",
        "            fightDetection2(input_path,intermid_output,image_folder,input_criminal_folder,list_criminal_images,output_face_folder,face_model=False)\n",
        "            model_call(fall_crash,intermid_output,output_path,fall_image_folder,crash_folder,mask_model=False)\n",
        "\n",
        "        # Fall, crash\n",
        "        elif my_model == 'fall_crash':\n",
        "            model_call(fall_crash,input_path,output_path,fall_image_folder,crash_folder)\n",
        "\n",
        "        # Fall, crash, mask\n",
        "        elif my_model == 'fall_crash_mask':\n",
        "            model_call(fall_crash,input_path,output_path,fall_image_folder,crash_folder,mask_model=True)\n",
        "\n",
        "        # Fight, Face, Fall\n",
        "        elif my_model == 'indoor':\n",
        "            list_criminal_images = os.listdir(input_criminal_folder)\n",
        "\n",
        "            fightDetection2(input_path,intermid_output,image_folder,input_criminal_folder,list_criminal_images,output_face_folder,face_model=True)\n",
        "            model_call(human_fall,intermid_output,output_path,fall_image_folder,crash_folder,mask_model=False)\n",
        "\n",
        "        # Fight, Face, Fall, Mask\n",
        "        elif my_model == 'indoor_mask':\n",
        "            list_criminal_images = os.listdir(input_criminal_folder)\n",
        "\n",
        "            fightDetection2(input_path,intermid_output,image_folder,input_criminal_folder,list_criminal_images,output_face_folder,face_model=True)\n",
        "            model_call(human_fall,intermid_output,output_path,fall_image_folder,crash_folder,mask_model=True)\n",
        "\n",
        "        # Fight, Face, Fall, Mask\n",
        "        elif my_model == 'fight_fall_mask':\n",
        "            list_criminal_images = os.listdir(input_criminal_folder)\n",
        "\n",
        "            fightDetection2(input_path,intermid_output,image_folder,input_criminal_folder,list_criminal_images,output_face_folder,face_model=False)\n",
        "            model_call(human_fall,intermid_output,output_path,fall_image_folder,crash_folder,mask_model=True)\n",
        "\n",
        "        # Fight, Face, Fall, Crash\n",
        "        elif my_model == 'general':\n",
        "            list_criminal_images = os.listdir(input_criminal_folder)\n",
        "\n",
        "            fightDetection2(input_path,intermid_output,image_folder,input_criminal_folder,list_criminal_images,output_face_folder,face_model=True)\n",
        "            model_call(fall_crash,intermid_output,output_path,fall_image_folder,crash_folder,mask_model=False)\n",
        "\n",
        "        # Fight, Face, Fall, Crash, Mask\n",
        "        elif my_model == 'general_mask':\n",
        "            list_criminal_images = os.listdir(input_criminal_folder)\n",
        "\n",
        "            fightDetection2(input_path,intermid_output,image_folder,input_criminal_folder,list_criminal_images,output_face_folder,face_model=True)\n",
        "            model_call(fall_crash,intermid_output,output_path,fall_image_folder,crash_folder,mask_model=True)\n",
        "\n",
        "        status = 'finished'\n",
        "    except Exception as e:\n",
        "        frame_number = -1\n",
        "        frame_count = 1\n",
        "        print(e)\n",
        "        return e\n",
        "    elapsed=time.time()-start\n",
        "\n",
        "    # else:\n",
        "    #     return \"Must enter model in the header...\", 400\n",
        "    print(\"-------------------------------processing done successfully-------------------------------\")\n",
        "    print(\"Take:\",f'{elapsed:.2f}',\" Second\")\n",
        "    print(\"Take:\",f'{elapsed/60:.2f}',\" min\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kb0tDFIKd5Mo"
      },
      "outputs": [],
      "source": [
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "def is_processing():\n",
        "    global frame_number\n",
        "    global frame_count\n",
        "\n",
        "    return (not (frame_number < 0) and frame_number*100/frame_count < 100 and status=='processing')\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def test():\n",
        "    global frame_number\n",
        "    global frame_count\n",
        "    percent = frame_number * 100 / frame_count\n",
        "\n",
        "    # this =\"<h1>The app is working frame_number = {}, frame_count = {}, percent = {} </h1>\".format(frame_number,frame_count, frame_number*100/frame_count)\n",
        "    return \"<h1>The app is working. frame_number = {}, frame_count = {}, percent = {}, model = {}</h1>\".format(frame_number, frame_count, f'{percent:.2f}', my_model)\n",
        "\n",
        "@app.route('/input', methods=['POST'])\n",
        "def video():\n",
        "    global frame_number\n",
        "    global frame_count\n",
        "    global status\n",
        "\n",
        "    response_data = {}\n",
        "    video_bytes = 0\n",
        "    if is_processing():\n",
        "        return 'wait for the last process to finish',400\n",
        "\n",
        "    content_type = request.headers.get('Content-Type')\n",
        "    print(content_type)\n",
        "    if content_type.startswith('multipart/form-data'):\n",
        "        # Receive the byte array from the HTTP request\n",
        "        files = request.files\n",
        "        video_bytes = files['video'].read()\n",
        "        print(\"Received Video in files\")\n",
        "\n",
        "    elif content_type == 'application/json':\n",
        "        json_data = request.json\n",
        "        video_bytes = base64.b64decode(json_data['video'])\n",
        "        print(\"Received Video in json\")\n",
        "\n",
        "    elif content_type == 'application/octet-stream' or content_type =='video/mp4':\n",
        "        video_bytes = request.data\n",
        "        print(\"Received Video in data\")\n",
        "\n",
        "    else:\n",
        "        print(\"Error Not received the video...\")\n",
        "        return \"Error Not received the video...\", 400\n",
        "\n",
        "    # Pathes\n",
        "    global input_path\n",
        "    global output_path\n",
        "\n",
        "    if video_bytes:\n",
        "        recreate('/content/input')\n",
        "        # convert the video back to file\n",
        "        with open(input_path, 'wb') as f:\n",
        "            f.write(video_bytes)\n",
        "    else:\n",
        "        print(\"Error Not received the video...\")\n",
        "        return \"Error Not received the video...\", 400\n",
        "\n",
        "    global id\n",
        "    global my_model\n",
        "\n",
        "    my_model = request.headers.get('X-model')\n",
        "    id = request.headers.get('X-id')\n",
        "    if not my_model:\n",
        "        print(\"Error Not received the model type...\")\n",
        "        return \"Error Not received the model type...\", 400\n",
        "    recreate('/content/output')\n",
        "\n",
        "    status = 'begin'\n",
        "    model_func(is_server_call=True)\n",
        "\n",
        "    print('Video was received successfully')\n",
        "    return 'Video was received successfully and have been processed...'\n",
        "\n",
        "@app.route('/model', methods=['POST'])\n",
        "def model_func(is_server_call=False):\n",
        "    global input_path\n",
        "    global my_model\n",
        "\n",
        "    global frame_number\n",
        "    global frame_count\n",
        "    if is_server_call:\n",
        "        print('model type choosed successfully to process The last video...')\n",
        "\n",
        "    else:\n",
        "        if is_processing():\n",
        "            return 'Please wait for the last process to finish',400\n",
        "\n",
        "        if not os.path.exists(input_path):\n",
        "            return 'Please send input video first to /input route!',400\n",
        "\n",
        "        my_model = request.headers.get('X-model')\n",
        "        if not my_model:\n",
        "            return \"Error Not received the model type...\", 400\n",
        "        print('model type choosed successfully to process the last video...')\n",
        "\n",
        "    threading.Thread(target=process).start()\n",
        "\n",
        "    return 'model type choosed successfully to process the last video...'\n",
        "\n",
        "\n",
        "@app.route('/response', methods=['POST'])\n",
        "def response():\n",
        "    print(status)\n",
        "    global input_path\n",
        "    global frame_number\n",
        "    global frame_count\n",
        "    global my_model\n",
        "\n",
        "    global image_folder\n",
        "    global output_face_folder\n",
        "    global fall_image_folder\n",
        "    global mask_image_folder\n",
        "\n",
        "    # Return The Response  TO Continue<--\n",
        "    response_data= {}\n",
        "    data = {}\n",
        "    response_data['status'] = 'failed'\n",
        "    response_data['percent'] = 0\n",
        "    response_data['trigger'] = False\n",
        "    response_data['data'] = None\n",
        "    response_data['msg'] = 'None'\n",
        "    response_data['model'] = my_model\n",
        "    response_data['id'] = id\n",
        "\n",
        "    if frame_number < 0:\n",
        "        response_data['status'] = 'failed'\n",
        "        response_data['percent'] = 0\n",
        "        response_data['trigger'] = False\n",
        "        response_data['data'] = None\n",
        "        response_data['msg'] = 'Please send input video and model first to /input route!'\n",
        "        response = jsonify(response_data)\n",
        "        return response\n",
        "\n",
        "    percent = frame_number*100/frame_count\n",
        "    response_data['percent'] = percent\n",
        "\n",
        "    if percent < 100 and status == 'processing':\n",
        "        response_data['status'] = 'processing'\n",
        "        data['video'] = None\n",
        "        data['images'] = None\n",
        "\n",
        "    elif status == 'finished':\n",
        "        response_data['status'] = 'finished'\n",
        "        response_data['trigger'] = True\n",
        "\n",
        "        # Adding video\n",
        "        # Convert the video back to a byte array\n",
        "        with open(output_path, 'rb') as f:\n",
        "            processed_video_bytes = f.read()\n",
        "\n",
        "        # processed_video_bytes variable as a string before passing it to jsonify()\n",
        "        data['video'] = base64.b64encode(processed_video_bytes).decode('utf-8')\n",
        "\n",
        "        # Adding images folder to response\n",
        "        data['images'] = list_images(image_folder,'fight')\n",
        "        data['images'] += list_images(output_face_folder,'face')\n",
        "        data['images'] += list_images(fall_image_folder,'fall')\n",
        "        data['images'] += list_images(crash_folder,'crash')\n",
        "\n",
        "    response_data['msg'] = 'response data sent successfully'\n",
        "    response_data['data'] = data\n",
        "    response = jsonify(response_data)\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mM7XAGNN4YRQ",
        "outputId": "f813a535-5430-4bc3-8c68-8e43cfafef2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-06-24T07:54:46+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To acces the Gloable link please click https://f4ec-34-143-197-241.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:8000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "port_no = 8000\n",
        "\n",
        "ngrok.set_auth_token(\"2ROjGpubBNIJvRPZ5FKz5cUGg22_6WWHGJe2LDxuzPQ8wRXAc\")\n",
        "\n",
        "# Run the App\n",
        "public_url =  ngrok.connect(port_no).public_url\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"To acces the Gloable link please click {public_url}\")\n",
        "    app.run(port=port_no)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
